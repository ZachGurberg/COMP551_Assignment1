{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to be used repeatedly\n",
    "def Verify(expression: bool, message: str):\n",
    "    if not expression:\n",
    "        raise Exception(message)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "def report_missing_features(X):\n",
    "    report = X.isna().sum(axis=1) \n",
    "    report = report[report > 0]\n",
    "    print(\"Entry index | Number of missing features\")\n",
    "    print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Number of missing values in the age prediction dataset: 0\n",
      "Report of missing features for breast cancer detection:\n",
      "Entry index | Number of missing features\n",
      "23     1\n",
      "40     1\n",
      "139    1\n",
      "145    1\n",
      "158    1\n",
      "164    1\n",
      "235    1\n",
      "249    1\n",
      "275    1\n",
      "292    1\n",
      "294    1\n",
      "297    1\n",
      "315    1\n",
      "321    1\n",
      "411    1\n",
      "617    1\n",
      "dtype: int64\n",
      "Number of missing values in the breast cancer prediction dataset: 16\n",
      "\n",
      "\n",
      " Datasets cleaned.\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### step 1 is to obtain the data and remove rows with missing features, we will store these in two objects of type dataset\n",
    "class dataset:\n",
    "    def __init__(self, features : np.ndarray, targets : np.ndarray, var_info : np.ndarray):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.var_info = var_info\n",
    "\n",
    "# fetch dataset for age predictions\n",
    "national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset = fetch_ucirepo(id=887) \n",
    "\n",
    "X = national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset.data.features\n",
    "missing_values = X.isna().sum().sum()\n",
    "if (missing_values>1):\n",
    "    print(\"Report of missing features for age prediction:\")\n",
    "    report_missing_features(X)\n",
    "print(\"Number of missing values in the age prediction dataset: \" + str(missing_values))\n",
    "nan_indices = X[X.isna().any(axis=1)].index\n",
    "X = X.dropna().to_numpy()\n",
    "\n",
    "y = national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset.data.targets\n",
    "y = y.drop(index=nan_indices)\n",
    "y = y.to_numpy()\n",
    "if not np.all((y == \"Adult\") | (y == \"Senior\")):\n",
    "    raise ValueError(\"Array contains an entry that is not 'Adult' or 'Senior'\")\n",
    "y = np.where(y == \"Senior\", 1, 0)\n",
    "\n",
    "Verify(len(X) == len(y), \"Features and targets are different lengths.\")\n",
    "var_info = np.array([\"Respondent Gender\", \"Activity\", \"BMI\", \"Blood Glucose\", \"Diabetic\", \"Oral\", \"Blood Insulin\"])\n",
    "ageDataset = dataset(X, y, var_info)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fetch dataset for breast cancer detection\n",
    "breast_cancer_wisconsin_original = fetch_ucirepo(id=15)  \n",
    "\n",
    "X = breast_cancer_wisconsin_original.data.features\n",
    "missing_values = X.isna().sum().sum()\n",
    "if (missing_values>1):\n",
    "    print(\"Report of missing features for breast cancer detection:\")\n",
    "    report_missing_features(X)\n",
    "print(\"Number of missing values in the breast cancer prediction dataset: \" + str(missing_values))\n",
    "nan_indices = X[X.isna().any(axis=1)].index\n",
    "X = X.dropna().to_numpy()\n",
    "\n",
    "y = breast_cancer_wisconsin_original.data.targets\n",
    "y = y.drop(index=nan_indices)\n",
    "y = y.to_numpy()\n",
    "if not np.all((y == 4) | (y == 2)):\n",
    "    raise ValueError(\"Array contains an entry that is not 4 or 2\")\n",
    "y = np.where(y == 4, 1, 0)\n",
    "\n",
    "\n",
    "Verify(len(X) == len(y), \"Features and targets are different lengths.\")\n",
    "var_info = np.array([\"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\"])\n",
    "breastDataset = dataset(X,y,var_info)\n",
    "\n",
    "print(\"\\n\\n Datasets cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Mean Positive  Mean Negative  Squared Difference\n",
      "Respondent Gender       1.508242       1.512017            0.000014\n",
      "Activity                1.909341       1.806165            0.010645\n",
      "BMI                    27.886264      27.968286            0.006728\n",
      "Blood Glucose         104.329670      98.644723           32.318625\n",
      "Diabetic                2.027473       2.014107            0.000179\n",
      "Oral                  141.208791     109.990596          974.575736\n",
      "Blood Insulin          10.405247      12.106661            2.894810\n",
      "                             Mean Positive  Mean Negative  Squared Difference\n",
      "Clump Thickness                   7.188285       2.963964           17.844884\n",
      "Uniformity of Cell Size           6.577406       1.306306           27.784490\n",
      "Uniformity of Cell Shape          6.560669       1.414414           26.483941\n",
      "Marginal Adhesion                 5.585774       1.346847           17.968504\n",
      "Single Epithelial Cell Size       5.326360       2.108108           10.357144\n",
      "Bare Nuclei                       7.627615       1.346847           39.448049\n",
      "Bland Chromatin                   5.974895       2.083333           15.144255\n",
      "Normal Nucleoli                   5.857741       1.261261           21.127622\n",
      "Mitoses                           2.602510       1.065315            2.362969\n"
     ]
    }
   ],
   "source": [
    "### Step 2 is to find the means in the positive and negative set for each features\n",
    "### We'll do this by going back to pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first for the age dataset\n",
    "targets = ageDataset.targets.squeeze()\n",
    "x = ageDataset.features.copy()\n",
    "positive_x = x[targets == 1]\n",
    "negative_x = x[targets == 0]\n",
    "means_positive = np.mean(positive_x, axis=0)\n",
    "means_negative = np.mean(negative_x, axis=0)\n",
    "squared_difference = np.power(means_positive-means_negative, 2)\n",
    "\n",
    "# tabling\n",
    "mean_values_df = pd.DataFrame({\n",
    "    'Mean Positive': means_positive,\n",
    "    'Mean Negative': means_negative,\n",
    "    'Squared Difference': squared_difference\n",
    "}, index=ageDataset.var_info)\n",
    "print(mean_values_df)\n",
    "\n",
    "\n",
    "#second for the breast dataset\n",
    "targets = breastDataset.targets.squeeze()\n",
    "x = breastDataset.features.copy()\n",
    "positive_x = x[targets == 1]\n",
    "negative_x = x[targets == 0]\n",
    "means_positive = np.mean(positive_x, axis=0)\n",
    "means_negative = np.mean(negative_x, axis=0)\n",
    "squared_difference = np.power(means_positive-means_negative, 2)\n",
    "\n",
    "# tabling\n",
    "mean_values_df = pd.DataFrame({\n",
    "    'Mean Positive': means_positive,\n",
    "    'Mean Negative': means_negative,\n",
    "    'Squared Difference': squared_difference\n",
    "}, index=breastDataset.var_info)\n",
    "print(mean_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3 is the implementation of the KNN model\n",
    "class KNN:\n",
    "    def __init__(self, distanceFunctor, k=1, weighted=True, normalize=True):\n",
    "        self.f = distanceFunctor\n",
    "        self.k = k\n",
    "        self.weighted = True\n",
    "        self.normalize = True\n",
    "\n",
    "    def fit(self, features : np.ndarray, targets : np.ndarray):\n",
    "        if self.normalize:\n",
    "            self.mins = np.min(features, axis = 0)\n",
    "            self.maxs = np.max(features, axis = 0)\n",
    "            self.features = (features - self.mins)/(self.maxs-self.mins)\n",
    "        else:\n",
    "            self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    #Returns a single lable -> Only works for binary classification (0,1).\n",
    "    #The returned value is the probability of the true label being 1\n",
    "    def predict(self, input:np.ndarray):\n",
    "        #We create a new vector where each value is the distance between the input and each feature vector\n",
    "        Verify(input.size == self.features.shape[1], \"Improper size of input vector during inferencing.\")\n",
    "        normalizedInput = input.__deepcopy__\n",
    "        if self.normalize:\n",
    "            normalizedInput = (input - self.mins)/(self.maxs-self.mins)\n",
    "        distances = self.f(normalizedInput, self.features) #one entry per row in the features matrix\n",
    "        smallestIndices = np.argpartition(distances, self.k)[:self.k]\n",
    "\n",
    "        #We can now access the K nearest labels and compute the probabilities\n",
    "        outputLabelUnclamped = 0.0\n",
    "        sumOfWeights = 0.0\n",
    "        for index in smallestIndices:\n",
    "            currentWeight = 1\n",
    "            if self.weighted:\n",
    "                epsilon = 1e-10\n",
    "                distance = self.f(self.features[index], normalizedInput) + epsilon #avoid division by 0\n",
    "                currentWeight = 1/distance #Weighted by current distance\n",
    "            sumOfWeights+=currentWeight\n",
    "            outputLabelUnclamped += self.targets[index]\n",
    "        outputLabelUnclamped/=sumOfWeights\n",
    "        return outputLabelUnclamped\n",
    "\n",
    "                \n",
    "#Our functor for computing similarity\n",
    "class EuclideanDistance:\n",
    "    def __call__(self, input_vector : np.ndarray, feature_matrix : np.ndarray):\n",
    "        return np.sqrt(np.sum((feature_matrix - input_vector)**2, axis=1)) #vectorized\n",
    "    \n",
    "\n",
    "def evaluate_acc(trueLabels, predictedLabels):\n",
    "    correctPredictions = np.sum(trueLabels == predictedLabels)\n",
    "    accuracy = correctPredictions/len(trueLabels)\n",
    "    return accuracy\n",
    "\n",
    "def SplitTrainTest(x:np.ndarray, y:np.ndarray, splitRatio = 0.8):\n",
    "    np.random.seed(420)\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    x_shuffled = x[indices]\n",
    "    y_shuffled = y[indices]\n",
    "    train_size = int(x.shape[0] * splitRatio)\n",
    "\n",
    "    x_train = x_shuffled[:train_size]\n",
    "    y_train = y_shuffled[:train_size]\n",
    "    x_test = x_shuffled[train_size:]\n",
    "    y_test = y_shuffled[train_size:]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def TestKNN(dataset, printDebug=False, threshold = 0.5, testOnTrain = False):\n",
    "    # A quick test to see if the KNN works\n",
    "    x = dataset.features\n",
    "    y = dataset.targets\n",
    "    if not testOnTrain:\n",
    "        x_train, y_train, x_test, y_test = SplitTrainTest(x, y)\n",
    "    else:\n",
    "        x_train = x\n",
    "        y_train = y\n",
    "        x_test = x\n",
    "        y_test = y\n",
    "\n",
    "    ks = [i for i in range(1,11)]\n",
    "    accuracies = []\n",
    "    for k in ks:\n",
    "        model = KNN(EuclideanDistance(), k=k)\n",
    "        model.fit(x_train, y_train)\n",
    "        # Initialize an empty list to store predicted probabilities\n",
    "        y_pred_prob = []\n",
    "        # Iterate over each instance in x_test\n",
    "        for instance in x_test:\n",
    "            # The model's predict method expects a 1D numpy array\n",
    "            prob = model.predict(instance.reshape(1, -1))\n",
    "            y_pred_prob.append(prob)\n",
    "        y_pred_prob = np.array(y_pred_prob)\n",
    "        # Threshold the probabilities to get binary predictions\n",
    "        y_pred = np.where(y_pred_prob > threshold, 1, 0)\n",
    "        accuracy = evaluate_acc(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        if printDebug:\n",
    "            print(f\"KNN accuracy for k = {k}: {accuracy*100:.2f}%\")\n",
    "    indexOfMax = np.argmax(accuracies)\n",
    "    return (accuracies[indexOfMax], ks[indexOfMax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy for k = 1: 81.75%\n",
      "KNN accuracy for k = 2: 84.67%\n",
      "KNN accuracy for k = 3: 87.59%\n",
      "KNN accuracy for k = 4: 88.32%\n",
      "KNN accuracy for k = 5: 87.59%\n",
      "KNN accuracy for k = 6: 86.86%\n",
      "KNN accuracy for k = 7: 88.32%\n",
      "KNN accuracy for k = 8: 91.24%\n",
      "KNN accuracy for k = 9: 91.24%\n",
      "KNN accuracy for k = 10: 91.24%\n",
      "Best accuracy KNN breast dataset: 91.24%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN accuracy for k = 1: 82.89%\n",
      "KNN accuracy for k = 2: 82.89%\n",
      "KNN accuracy for k = 3: 82.89%\n",
      "KNN accuracy for k = 4: 82.89%\n",
      "KNN accuracy for k = 5: 82.89%\n",
      "KNN accuracy for k = 6: 82.89%\n",
      "KNN accuracy for k = 7: 82.89%\n",
      "KNN accuracy for k = 8: 82.89%\n",
      "KNN accuracy for k = 9: 82.89%\n",
      "KNN accuracy for k = 10: 82.89%\n",
      "Best accuracy KNN age dataset: 82.89%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN accuracy for k = 1: 81.75%\n",
      "KNN accuracy for k = 2: 84.67%\n",
      "KNN accuracy for k = 3: 87.59%\n",
      "KNN accuracy for k = 4: 88.32%\n",
      "KNN accuracy for k = 5: 87.59%\n",
      "KNN accuracy for k = 6: 86.86%\n",
      "KNN accuracy for k = 7: 88.32%\n",
      "KNN accuracy for k = 8: 91.24%\n",
      "KNN accuracy for k = 9: 91.24%\n",
      "KNN accuracy for k = 10: 91.24%\n",
      "Best accuracy for KNN breast dataset on test data at k = 8: 91.24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN accuracy for k = 1: 82.89%\n",
      "KNN accuracy for k = 2: 82.89%\n",
      "KNN accuracy for k = 3: 82.89%\n",
      "KNN accuracy for k = 4: 82.89%\n",
      "KNN accuracy for k = 5: 82.89%\n",
      "KNN accuracy for k = 6: 82.89%\n",
      "KNN accuracy for k = 7: 82.89%\n",
      "KNN accuracy for k = 8: 82.89%\n",
      "KNN accuracy for k = 9: 82.89%\n",
      "KNN accuracy for k = 10: 82.89%\n",
      "Best accuracy for KNN age dataset on test data at k = 1: 82.89\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN accuracy for k = 1: 65.01%\n",
      "KNN accuracy for k = 2: 65.01%\n",
      "KNN accuracy for k = 3: 65.01%\n",
      "KNN accuracy for k = 4: 65.01%\n",
      "KNN accuracy for k = 5: 65.01%\n",
      "KNN accuracy for k = 6: 65.01%\n",
      "KNN accuracy for k = 7: 65.01%\n",
      "KNN accuracy for k = 8: 65.01%\n",
      "KNN accuracy for k = 9: 65.01%\n",
      "KNN accuracy for k = 10: 65.01%\n",
      "Best accuracy for KNN breast dataset on train data at k = 1: 65.01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN accuracy for k = 1: 84.02%\n",
      "KNN accuracy for k = 2: 84.02%\n",
      "KNN accuracy for k = 3: 84.02%\n",
      "KNN accuracy for k = 4: 84.02%\n",
      "KNN accuracy for k = 5: 84.02%\n",
      "KNN accuracy for k = 6: 84.02%\n",
      "KNN accuracy for k = 7: 84.02%\n",
      "KNN accuracy for k = 8: 84.02%\n",
      "KNN accuracy for k = 9: 84.02%\n",
      "KNN accuracy for k = 10: 84.02%\n",
      "Best accuracy for KNN age dataset of train data at k = 1: 84.02\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Task 3: Running experiments\n",
    "\n",
    "#1. Compare the accuracy and AUROC of KNN and DT algorithm on the two datasets\n",
    "\n",
    "#1.1 Accuracy of KNN on both datasets\n",
    "printDebug = True ##change to false to hide the accuracy for each k\n",
    "breastAccuracyKNN, k = TestKNN(dataset=breastDataset, printDebug=printDebug)\n",
    "print(f\"Best accuracy KNN breast dataset: {breastAccuracyKNN*100:.2f}%\" + \"\\n\\n\\n\\n\")\n",
    "ageAccuracyKNN, k = TestKNN(dataset=ageDataset, printDebug = printDebug)\n",
    "print(f\"Best accuracy KNN age dataset: {ageAccuracyKNN*100:.2f}%\" + \"\\n\\n\\n\\n\")\n",
    "\n",
    "#2 Test different K values to see how it affects training data accuracy and test data accuracy of the KNN\n",
    "accuracy, k = TestKNN(dataset=breastDataset, printDebug = True) #First this is accuracy on the test dataset with a train/test split\n",
    "print(f\"Best accuracy for KNN breast dataset on test data at k = {k}: {accuracy*100:.2f}\" + \"\\n\\n\\n\\n\\n\")\n",
    "accuracy, k =TestKNN(dataset=ageDataset, printDebug=True)\n",
    "print(f\"Best accuracy for KNN age dataset on test data at k = {k}: {accuracy*100:.2f}\" + \"\\n\\n\\n\\n\\n\")\n",
    "accuracy, k =TestKNN(dataset=breastDataset, printDebug=True, testOnTrain=True) #Now this is accuracy on the train dataset\n",
    "print(f\"Best accuracy for KNN breast dataset on train data at k = {k}: {accuracy*100:.2f}\" + \"\\n\\n\\n\\n\\n\")\n",
    "accuracy, k =TestKNN(dataset=ageDataset, printDebug=True, testOnTrain=True)\n",
    "print(f\"Best accuracy for KNN age dataset of train data at k = {k}: {accuracy*100:.2f}\" + \"\\n\\n\\n\\n\\n\")\n",
    "\n",
    "#4 Try out different cost functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GrITPythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
